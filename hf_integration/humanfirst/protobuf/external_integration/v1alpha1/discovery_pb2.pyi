"""
@generated by mypy-protobuf.  Do not edit manually!
isort:skip_file
"""
import builtins
import google.protobuf.descriptor
import google.protobuf.message
import sys

if sys.version_info >= (3, 8):
    import typing as typing_extensions
else:
    import typing_extensions

DESCRIPTOR: google.protobuf.descriptor.FileDescriptor

class GetCapabilitiesRequest(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    def __init__(
        self,
    ) -> None: ...

global___GetCapabilitiesRequest = GetCapabilitiesRequest

class GetCapabilitiesResponse(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    SUPPORTS_MODELS_FIELD_NUMBER: builtins.int
    SUPPORTS_WORKSPACES_FIELD_NUMBER: builtins.int
    MAX_CONCURRENT_MODELS_FIELD_NUMBER: builtins.int
    MODEL_CLASSIFICATION_BATCH_SIZE_FIELD_NUMBER: builtins.int
    supports_models: builtins.bool
    """True if this integration supports externally trained embedding models."""
    supports_workspaces: builtins.bool
    """True if this integration supports importing and exporting workspaces."""
    max_concurrent_models: builtins.int
    """If non-zero, the amount of concurrent models being trained, or loaded, will be limited to this number"""
    model_classification_batch_size: builtins.int
    """If non-zero, specifies the maximum number of examples in a single Classify request"""
    def __init__(
        self,
        *,
        supports_models: builtins.bool = ...,
        supports_workspaces: builtins.bool = ...,
        max_concurrent_models: builtins.int = ...,
        model_classification_batch_size: builtins.int = ...,
    ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["max_concurrent_models", b"max_concurrent_models", "model_classification_batch_size", b"model_classification_batch_size", "supports_models", b"supports_models", "supports_workspaces", b"supports_workspaces"]) -> None: ...

global___GetCapabilitiesResponse = GetCapabilitiesResponse
